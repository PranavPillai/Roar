{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import mord \n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOG DATA WRANGLING\n",
    "train = pd.read_csv('train.csv')\n",
    "train.dropna(inplace=True)\n",
    "train_dogs = train[train['Type'] == 1]\n",
    "train_dogs_adoption_speed_old = train_dogs['AdoptionSpeed']\n",
    "train_type_id = train_dogs[['Type', 'PetID']]\n",
    "\n",
    "train_dogs_adoption_speed = []\n",
    "for i in train_dogs_adoption_speed_old:\n",
    "    if i <= 3:\n",
    "        train_dogs_adoption_speed.append(0)\n",
    "    else: \n",
    "        train_dogs_adoption_speed.append(1)\n",
    "\n",
    "data_dogs = {}\n",
    "train_dogs_magnitudes = [];\n",
    "train_dogs_scores = [];\n",
    "test_dogs_magnitudes = [];\n",
    "test_dogs_scores = [];\n",
    "\n",
    "# Clean up json files just for dogs\n",
    "for root, dirs, files in os.walk(\"train_sentiment\"):\n",
    "    for filename in files:\n",
    "        loc = train_type_id.loc[train_type_id['PetID'] == filename[0:len(filename)-5]]\n",
    "        if len(loc.index) > 0 and filename.endswith(\".json\"):\n",
    "            data_file_name = 'train_sentiment/' + filename\n",
    "            data_dogs = json.load(open(data_file_name, 'r'))\n",
    "            train_dogs_magnitudes.append(data_dogs[\"documentSentiment\"][\"magnitude\"])\n",
    "            train_dogs_scores.append(data_dogs[\"documentSentiment\"][\"score\"])\n",
    "            \n",
    "df_train_dogs_magnitudes = pd.DataFrame(train_dogs_magnitudes)\n",
    "df_train_dogs_scores = pd.DataFrame(train_dogs_scores)\n",
    "df_train_dogs_adoption_speed = pd.DataFrame(train_dogs_adoption_speed)\n",
    "\n",
    "horizontal_dogs_train_df = pd.concat([df_train_dogs_magnitudes, df_train_dogs_scores, df_train_dogs_adoption_speed], axis=1)\n",
    "horizontal_dogs_train_df.columns = ['train_dogs_magnitudes', 'train_dogs_scores', 'train_dogs_adoption_speed']\n",
    "horizontal_dogs_train_df.dropna(inplace = True)\n",
    "\n",
    "features_train_dogs = ['train_dogs_magnitudes']\n",
    "# Decision trees, SVM, Linear SVM, Nearest Neighbors, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAT DATA WRANGLING\n",
    "train = pd.read_csv('train.csv')\n",
    "train.dropna(inplace=True)\n",
    "train_cats = train[train['Type'] == 2]\n",
    "train_cats_adoption_speed_old = train_cats['AdoptionSpeed']\n",
    "train_type_cats_id = train_cats[['Type', 'PetID']]\n",
    "\n",
    "train_cats_adoption_speed = []\n",
    "for i in train_cats_adoption_speed_old:\n",
    "    if i <= 3:\n",
    "        train_cats_adoption_speed.append(0)\n",
    "    else:\n",
    "        train_cats_adoption_speed.append(1)\n",
    "\n",
    "data_cats = {}\n",
    "train_cats_magnitudes = [];\n",
    "train_cats_scores = [];\n",
    "test_cats_magnitudes = [];\n",
    "test_cats_scores = [];\n",
    "\n",
    "# Clean up json files just for dogs\n",
    "for root, dirs, files in os.walk(\"train_sentiment\"):\n",
    "    for filename in files:\n",
    "        loc = train_type_cats_id.loc[train_type_cats_id['PetID'] == filename[0:len(filename)-5]]\n",
    "        if len(loc.index) > 0 and filename.endswith(\".json\"):\n",
    "            data_file_name = 'train_sentiment/' + filename;\n",
    "            data_cats = json.load(open(data_file_name, 'r'))\n",
    "            train_cats_magnitudes.append(data_cats[\"documentSentiment\"][\"magnitude\"])\n",
    "            train_cats_scores.append(data_cats[\"documentSentiment\"][\"score\"])\n",
    "            \n",
    "df_train_cats_magnitudes = pd.DataFrame(train_cats_magnitudes)\n",
    "df_train_cats_scores = pd.DataFrame(train_cats_scores)\n",
    "df_train_cats_adoption_speed = pd.DataFrame(train_cats_adoption_speed)\n",
    "\n",
    "horizontal_cats_train_df = pd.concat([df_train_cats_magnitudes, df_train_cats_scores, df_train_cats_adoption_speed], axis=1)\n",
    "horizontal_cats_train_df.columns = ['train_cats_magnitudes', 'train_cats_scores', 'train_cats_adoption_speed']\n",
    "horizontal_cats_train_df.dropna(inplace = True)\n",
    "\n",
    "features_train_cats = ['train_cats_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2664\n",
      "1    1055\n",
      "Name: train_dogs_adoption_speed, dtype: int64\n",
      "The score of the dogs model is (TRAIN): 0.716322\n",
      "-------------\n",
      "The score of the dogs model is (TEST): 0.707527\n",
      "-------------\n",
      "The best params for logistic regression on dogs is: {'C': 1} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Dog Data\n",
    "X = horizontal_dogs_train_df[features_train_dogs]\n",
    "y = horizontal_dogs_train_df['train_dogs_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=777)\n",
    "print(pd.DataFrame(y_train)['train_dogs_adoption_speed'].value_counts())\n",
    "\n",
    "parameters = {'C':[1, 5, 10]}\n",
    "lg = LogisticRegression(penalty='l2', solver='newton-cg', random_state=777, max_iter=10000, tol=10)\n",
    "clf = GridSearchCV(lg, parameters, cv=5, refit='True')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The score of the dogs model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on dogs is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2590\n",
      "1     875\n",
      "Name: train_cats_adoption_speed, dtype: int64\n",
      "The score of the cats model is (TRAIN): 0.747475\n",
      "-------------\n",
      "The score of the cats model is (TEST): 0.739507\n",
      "-------------\n",
      "The best params for logistic regression on cats is: {'C': 1} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.628765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Cat Data\n",
    "X = horizontal_cats_train_df.loc[:, features_train_cats]\n",
    "y = horizontal_cats_train_df['train_cats_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(pd.DataFrame(y_train)['train_cats_adoption_speed'].value_counts())\n",
    "\n",
    "parameters = {'C':[1, 5, 10]}\n",
    "lg = LogisticRegression(penalty='l2', solver='newton-cg', random_state=777, max_iter=10000, tol=10)\n",
    "clf = GridSearchCV(lg, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The score of the cats model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on cats is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_df = pd.DataFrame(y_pred);\n",
    "y_test_df = pd.DataFrame(y_test);\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3161\n",
      "1    1302\n",
      "Name: train_dogs_adoption_speed, dtype: int64\n",
      "The score of the dogs model is (TRAIN): 0.708940\n",
      "-------------\n",
      "The score of the dogs model is (TEST): 0.717406\n",
      "-------------\n",
      "The best params for logistic regression on dogs is: {'max_depth': 3} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.599983\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees on Dog Data\n",
    "X = horizontal_dogs_train_df.loc[:, features_train_dogs]\n",
    "y = horizontal_dogs_train_df['train_dogs_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(pd.DataFrame(y_train)['train_dogs_adoption_speed'].value_counts())\n",
    "\n",
    "parameters = {'max_depth': np.arange(3, 10)}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "clf = GridSearchCV(dt, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The score of the dogs model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on dogs is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2590\n",
      "1     875\n",
      "Name: train_cats_adoption_speed, dtype: int64\n",
      "The score of the cats model is (TRAIN): 0.747763\n",
      "-------------\n",
      "The score of the cats model is (TEST): 0.739507\n",
      "-------------\n",
      "The best params for logistic regression on cats is: {'max_depth': 3} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.628765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees on CAT Data\n",
    "X = horizontal_cats_train_df.loc[:, features_train_cats]\n",
    "y = horizontal_cats_train_df['train_cats_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(pd.DataFrame(y_train)['train_cats_adoption_speed'].value_counts())\n",
    "\n",
    "parameters = {'C':[1, 5, 10]}\n",
    "parameters = {'max_depth': np.arange(3, 10)}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The score of the cats model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on cats is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3161\n",
      "1    1302\n",
      "Name: train_dogs_adoption_speed, dtype: int64\n",
      "-------------\n",
      "The score of the dogs model is (TRAIN): 0.693256\n",
      "-------------\n",
      "The score of the dogs model is (TEST): 0.698925\n",
      "-------------\n",
      "The best params for logistic regression on dogs is: {'n_neighbors': 4} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.603421\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors on DOG Data\n",
    "X = horizontal_dogs_train_df.loc[:, features_train_dogs]\n",
    "y = horizontal_dogs_train_df['train_dogs_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(pd.DataFrame(y_train)['train_dogs_adoption_speed'].value_counts())\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [3, 4, 5]}\n",
    "clf = GridSearchCV(neigh, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on dogs is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "The score of the cats model is (TRAIN): 0.608658\n",
      "-------------\n",
      "The score of the cats model is (TEST): 0.610125\n",
      "-------------\n",
      "The best params for logistic regression on cats is: {'n_neighbors': 4} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.615983\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors on CAT Data\n",
    "X = horizontal_cats_train_df.loc[:, features_train_cats]\n",
    "y = horizontal_cats_train_df['train_cats_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "neigh = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [3, 4, 5]}\n",
    "clf = GridSearchCV(neigh, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on cats is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "The score of the dogs model is (TRAIN): 0.708268\n",
      "-------------\n",
      "The score of the dogs model is (TEST): 0.717406\n",
      "-------------\n",
      "The best params for logistic regression on dogs is: {'C': 0.001} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.599359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC on DOG Data\n",
    "X = horizontal_dogs_train_df.loc[:, features_train_dogs]\n",
    "y = horizontal_dogs_train_df['train_dogs_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "svc = LinearSVC(random_state=0, tol=1e-5, max_iter=1000)\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the dogs model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on dogs is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "The score of the cats model is (TRAIN): 0.747475\n",
      "-------------\n",
      "The score of the cats model is (TEST): 0.739507\n",
      "-------------\n",
      "The best params for logistic regression on cats is: {'C': 0.001} \n",
      "-------------\n",
      "The F1 score for the dogs model is (TEST): 0.628765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC on CAT Data\n",
    "X = horizontal_cats_train_df.loc[:, features_train_cats]\n",
    "y = horizontal_cats_train_df['train_cats_adoption_speed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "svc = LinearSVC(random_state=0, tol=1e-5)\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TRAIN): %f\" % clf.score(X_train, y_train))\n",
    "print(\"-------------\")\n",
    "print(\"The score of the cats model is (TEST): %f\" % clf.score(X_test, y_test))\n",
    "print(\"-------------\")\n",
    "print(\"The best params for logistic regression on cats is: %s \" % clf.best_params_)\n",
    "print(\"-------------\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"The F1 score for the dogs model is (TEST): %f\" % f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
